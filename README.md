# mLLM ðŸ”¥

ä¸€ä¸ªä»Žé›¶å¼€å§‹å®žçŽ°çš„è½»é‡çº§å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†æ¡†æž¶ï¼Œä½¿ç”¨ C++ ç¼–å†™ï¼Œä¸“æ³¨äºŽå­¦ä¹ å’Œç†è§£ Transformer æž¶æž„çš„åº•å±‚å®žçŽ°ï¼

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- **ðŸ¤– æ¨¡åž‹æ”¯æŒ**: ç›®å‰æ”¯æŒ Qwen3-0.6B æ¨¡åž‹ï¼Œç›´æŽ¥å…¼å®¹ Hugging Face å®˜æ–¹æ¨¡åž‹æ–‡ä»¶æ ¼å¼
- **âš¡ åŒåŽç«¯æ”¯æŒ**: åŒæ—¶å®žçŽ°äº† CUDA å’Œ CPU ç®—å­ï¼Œæ”¯æŒ GPU åŠ é€Ÿå’Œ CPU æŽ¨ç†
- **ðŸ“ BPE Tokenizer**: è‡ªä¸»å®žçŽ°çš„å­—èŠ‚å¯¹ç¼–ç åˆ†è¯å™¨
- **ðŸ’¾ KV Cache**: å®žçŽ°äº†é”®å€¼ç¼“å­˜æœºåˆ¶ï¼Œæå‡æŽ¨ç†æ•ˆçŽ‡

## ðŸ›ï¸ é¡¹ç›®ç»“æž„

```
MiniLLM/
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ base/                  # åŸºç¡€ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ allocator.h        # å†…å­˜åˆ†é…å™¨
â”‚   â”‚   â”œâ”€â”€ buffer.h           # æ•°æ®ç¼“å†²åŒº
â”‚   â”‚   â”œâ”€â”€ common.h           # é€šç”¨å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ json.hpp           # JSON è§£æžåº“
â”‚   â”‚   â”œâ”€â”€ safetensors.h      # SafeTensors æ–‡ä»¶è§£æž
â”‚   â”‚   â”œâ”€â”€ tensor.h           # å¼ é‡ç±»å®šä¹‰
â”‚   â”‚   â””â”€â”€ util.h             # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ kernel/                # è®¡ç®—å†…æ ¸
â”‚   â”‚   â”œâ”€â”€ cpu/               # CPU ç®—å­å®žçŽ°
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ cuda/              # CUDA ç®—å­å®žçŽ°
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ kernel.h           # å†…æ ¸æŽ¥å£
â”‚   â”œâ”€â”€ model/                 # æ¨¡åž‹æž¶æž„
â”‚   â”‚   â”œâ”€â”€ qwen3.h            # Qwen3 ä¸»æ¨¡åž‹
â”‚   â”‚   â”œâ”€â”€ qwen3_decode_layer.h    # è§£ç å±‚
â”‚   â”‚   â”œâ”€â”€ qwen3_mlp.h        # å¤šå±‚æ„ŸçŸ¥æœº
â”‚   â”‚   â”œâ”€â”€ qwen3_rotary_embedding.h # æ—‹è½¬ä½ç½®ç¼–ç 
â”‚   â”‚   â””â”€â”€ qwen3_self_attn.h  # è‡ªæ³¨æ„åŠ›æœºåˆ¶
â”‚   â”œâ”€â”€ op/                    # ç®—å­å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ add.h              # åŠ æ³•æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ causal_mask.h      # å› æžœæŽ©ç 
â”‚   â”‚   â”œâ”€â”€ ele_mul.h          # å…ƒç´ ä¹˜æ³•
â”‚   â”‚   â”œâ”€â”€ embedding.h        # åµŒå…¥å±‚
â”‚   â”‚   â”œâ”€â”€ layer.h            # å±‚åŸºç±»
â”‚   â”‚   â”œâ”€â”€ linear.h           # çº¿æ€§å±‚
â”‚   â”‚   â”œâ”€â”€ mat_mul.h          # çŸ©é˜µä¹˜æ³•
â”‚   â”‚   â”œâ”€â”€ rms_norm.h         # RMS å½’ä¸€åŒ–
â”‚   â”‚   â”œâ”€â”€ silu.h             # SiLU æ¿€æ´»å‡½æ•°
â”‚   â”‚   â””â”€â”€ softmax.h          # Softmax æ“ä½œ
â”‚   â””â”€â”€ tokenizer/             # åˆ†è¯å™¨
â”‚       â””â”€â”€ tokenizer.h        # åˆ†è¯å™¨æŽ¥å£
â”œâ”€â”€ src/                       # æºæ–‡ä»¶å®žçŽ°
â”‚   â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ kernel/
â”‚   â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ op/
â”‚   â”œâ”€â”€ tokenizer/
â”‚   â””â”€â”€ CMakeLists.txt
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ qwen3_chat.cpp         # Qwen3 èŠå¤©æ¼”ç¤º
â”‚   â””â”€â”€ CMakeLists.txt
â”œâ”€â”€ test/                      # æµ‹è¯•ç¨‹åº
â”œâ”€â”€ scripts/                   # è¾…åŠ©è„šæœ¬
â”œâ”€â”€ CMakeLists.txt
â””â”€â”€ README.md
```

## Qwen3 æž¶æž„å›¾
![Qwen3æž¶æž„å›¾](https://github.com/BowTen/mLLM/raw/main/resources/qwen3_arc.png)

## èŠå¤©ç¤ºä¾‹

```cpp
#include "model/qwen3.h"

using namespace mllm;
using namespace mllm::tokenizer;

class Qwen3Chat
{
public:
    Qwen3Chat(const std::string &model_path, mllm::base::Device device, float temperature)
        : model(mllm::model::Qwen3::from_pretrained(model_path, device, temperature)),
          tokenizer(model.get_tokenizer())
    {
    }

    std::string chat(const std::string &input)
    {
        auto chat_token_ids = tokenizer->encode_with_chat_template(input, true, true);
        auto input_id = tokenizer->to_tensor(chat_token_ids, model.device());
        base::Tensor next_id({1, 1}, model.device(), false, model.stream());

        std::string output;
        while (true)
        {
            input_id.toDevice(model.device());
            next_id.toDevice(model.device());
            model.forward(input_id, next_id);
            next_id.toDevice(base::Device::CPU);
            uint32_t id = *(reinterpret_cast<uint32_t *>(next_id.data()));

            std::string next_token = tokenizer->decode(id);
            output.append(next_token);

            if (id == BPETokenizer::QWEN3_END_OF_TEXT || id == BPETokenizer::QWEN3_IM_END)
            {
                std::cout << std::endl;
                break;
            }
            std::cout << next_token;
            std::cout.flush();
            input_id = next_id.clone();
        }

        return output;
    }

private:
    mllm::model::Qwen3 model;
    BPETokenizerPtr tokenizer;
};

int main()
{
    std::string model_path = "path_to_your_resources/Qwen/Qwen3-0.6B";
    std::cout << "Loading model..." << std::endl;
    Qwen3Chat qwen3(model_path, base::Device::CUDA, 0.6);
    std::cout << "Loading accomplished." << std::endl;

    while (true)
    {
        std::string input;
        std::cout << "User: ";
        std::cin >> input;
        if (input == "exit")
            break;
        std::cout << "Qwen3: ";
        std::cout.flush();
        qwen3.chat(input);
    }

    return 0;
}
```

## ä¾èµ–åº“

- armadillo
- glog
- gtest